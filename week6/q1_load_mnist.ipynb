{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(   # (b, 1, 28, 28)\n",
    "            nn.Conv2d(1, 8, 3),    # (b, 8, 26, 26)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),     # (b, 8, 13, 13)\n",
    "            nn.Conv2d(8, 16, 3),  # (b, 16, 11, 11)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, padding=1),      # (b, 16, 6, 6)\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        feature_size = self.get_net_dims()\n",
    "        self.classification = nn.Sequential(\n",
    "            nn.Linear(feature_size, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 10)            \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.net(x)\n",
    "        return self.classification(features)\n",
    "    \n",
    "    def get_net_dims(self):\n",
    "        x = torch.randn(1, 1, 28, 28)\n",
    "        y = self.net(x)\n",
    "        return y.numel()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (net): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (classification): Sequential(\n",
       "    (0): Linear(in_features=576, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN().to(device)\n",
    "model.load_state_dict(torch.load('./models/mnist_cnn_model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 4\n",
    "\n",
    "mytf = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "train_data = datasets.MNIST(root = './data', train=True, download=True, transform=mytf)\n",
    "test_data = datasets.MNIST(root = './data', train=False, download=True, transform=mytf)\n",
    "\n",
    "train_loader = DataLoader(train_data, batchSize, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batchSize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1399 correct out of 10000\n",
      "Accuracy = 13.99%\n"
     ]
    }
   ],
   "source": [
    "correct_count = 0\n",
    "for input, target in test_loader:\n",
    "    input, target = input.to(device), target.to(device)\n",
    "    output = model(input)\n",
    "\n",
    "    correct_count += sum(output.argmax(1) == target).item()\n",
    "\n",
    "print(f\"{correct_count} correct out of {len(test_data)}\")\n",
    "print(f'Accuracy = {correct_count/len(test_data) * 100}%')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning (if desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = torch.load('./checkpoints/fashion_mnist_10.pth')\n",
    "checkpoints.keys()\n",
    "\n",
    "start_epoch = checkpoints['eopch']\n",
    "model.load_state_dict(checkpoints['model_state_dict'])\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "optimizer.load_state_dict(checkpoints['optimizer_state_dict'])\n",
    "\n",
    "criteria = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 11/5: Loss = 0.15200; \tVal Loss = 20.54652; \tAcc = 12.66\n",
      "Ep 12/5: Loss = 0.14505; \tVal Loss = 18.17535; \tAcc = 14.23\n",
      "Ep 13/5: Loss = 0.13860; \tVal Loss = 23.02817; \tAcc = 9.83\n",
      "Ep 14/5: Loss = 0.13249; \tVal Loss = 19.22543; \tAcc = 10.87\n",
      "Ep 15/5: Loss = 0.12606; \tVal Loss = 25.00200; \tAcc = 10.57\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "val_loss_list = []\n",
    "accuracies = []\n",
    "epochs = 5\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    outputs = outputs.argmax(1)\n",
    "    correct = sum(outputs == labels).item()\n",
    "    return correct/len(outputs) * 100\n",
    "\n",
    "\n",
    "for ep in range(start_epoch, epochs + start_epoch):\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0\n",
    "    running_val_loss = 0\n",
    "    running_accuracy = 0\n",
    "    \n",
    "    for input, label in train_loader:\n",
    "        input, label = input.to(device), label.to(device)\n",
    "        \n",
    "        output = model(input)\n",
    "        \n",
    "        loss = criteria(output, label)\n",
    "        running_loss += loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    loss_list.append(avg_loss.item())\n",
    "    \n",
    "    model.eval()\n",
    "    for input, label in test_loader:\n",
    "        input, label = input.to(device), label.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(input)\n",
    "        \n",
    "        val_loss = criteria(output, label)\n",
    "        running_val_loss += val_loss\n",
    "        \n",
    "        running_accuracy += accuracy(output, label)\n",
    "    \n",
    "    avg_val_loss = running_val_loss / len(test_loader)\n",
    "    avg_accuracy = running_accuracy / len(test_loader)\n",
    "    val_loss_list.append(avg_val_loss.item())\n",
    "    accuracies.append(avg_accuracy)\n",
    "        \n",
    "        \n",
    "    \n",
    "    print(f\"Ep {ep+1}/{epochs + start_epoch}: Loss = {avg_loss:.5f}; \\tVal Loss = {avg_val_loss:.5f}; \\tAcc = {avg_accuracy}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
